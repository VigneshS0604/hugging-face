{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98075530",
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_key=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e9c0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c1d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=sec_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6d1fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "llm=HuggingFaceEndpoint(repo_id=repo_id,max_length=128,temperature=0.7,token=sec_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1800f113",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(\"what can we do using machine lerningabout it?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49d104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "question=\"Who won the Cricket World Cup in the year 2011?\"\n",
    "template = \"\"\"Question: {question}\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa0636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain=LLMChain(llm=llm,prompt=prompt)\n",
    "print(llm_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7f6fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a2b420",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id=\"gpt2\"\n",
    "model=AutoModelForCausalLM.from_pretrained(model_id)\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaa39be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe=pipeline(\"text-generation\",model=model,tokenizer=tokenizer,max_new_tokens=100)\n",
    "hf=HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64f1d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0664c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.invoke(\"What is machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a175dff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline\n",
    "\n",
    "# Initialize the HuggingFacePipeline with the GPT-2 model\n",
    "gpu_llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"gpt2\",\n",
    "    task=\"text-generation\",\n",
    "    device_map=\"auto\",  # Use the accelerate library for device placement\n",
    "    pipeline_kwargs={\"max_new_tokens\": 100},\n",
    ")\n",
    "\n",
    "# Function to ask a question to the LLM\n",
    "def ask_question(question: str):\n",
    "    response = gpu_llm.invoke(question)\n",
    "    return response\n",
    "\n",
    "# Get user input and invoke the model\n",
    "question = input(\"Enter The Question: \")\n",
    "response = ask_question(question)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3e0a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "emplate = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff13bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=prompt|gpu_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1d14f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "question=input(\"Enter The Question: \")\n",
    "chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dec88c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edafc95b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba555a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725cb1d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c2c828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094facc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888d449f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d4680c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00c5e33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719a2ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "import os\n",
    "\n",
    "# Set your Hugging Face API token\n",
    "sec_key = \"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\"\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = sec_key\n",
    "\n",
    "# Repository ID for the model\n",
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "# Initialize the HuggingFaceEndpoint\n",
    "llm = HuggingFaceEndpoint(repo_id=repo_id, max_length=128, temperature=0.7, token=sec_key)\n",
    "\n",
    "# Function to ask questions to the LLM\n",
    "def ask_question(question: str):\n",
    "    response = llm.invoke(question)\n",
    "    return response\n",
    "\n",
    "# Interactive session where the user can ask questions\n",
    "def interactive_session():\n",
    "    print(\"Welcome! Ask your questions about machine learning or any other topic. Type 'exit' to end the session.\")\n",
    "    while True:\n",
    "        user_question = input(\"Your question: \")\n",
    "        if user_question.lower() == 'exit':\n",
    "            print(\"Exiting the session. Goodbye!\")\n",
    "            break\n",
    "        response = ask_question(user_question)\n",
    "        print(\"Response:\", response)\n",
    "\n",
    "# Start the interactive session\n",
    "interactive_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dea18c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface-hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a4e84d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44501068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from translate import Translator\n",
    "from langdetect import detect\n",
    "\n",
    "def translate_text(text, to_lang):\n",
    "    try:\n",
    "        # Detect the language of the input text\n",
    "        from_lang = detect(text)\n",
    "        translator = Translator(from_lang=from_lang, to_lang=to_lang)\n",
    "        translation = translator.translate(text)\n",
    "        return translation\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Get input from the user\n",
    "    text_to_translate = input(\"Enter the text to translate: \")\n",
    "    to_language = input(\"Enter the code for the target language (e.g., 'es' for Spanish): \")\n",
    "    \n",
    "    # Perform translation\n",
    "    translated_text = translate_text(text_to_translate, to_language)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"\\nOriginal text: {text_to_translate}\")\n",
    "    print(f\"Translated text: {translated_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ffa8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from translate import Translator\n",
    "from langdetect import detect\n",
    "\n",
    "def translate_text(text, to_lang):\n",
    "    try:\n",
    "        # Detect the language of the input text\n",
    "        from_lang = detect(text)\n",
    "        translator = Translator(from_lang=from_lang, to_lang=to_lang)\n",
    "        translation = translator.translate(text)\n",
    "        return translation\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Get input from the user\n",
    "    text_to_translate = input(\"Enter the text to translate: \")\n",
    "    to_language = input(\"Enter the code for the target language (e.g., 'es' for Spanish): \")\n",
    "    \n",
    "    # Perform translation\n",
    "    translated_text = translate_text(text_to_translate, to_language)\n",
    "    \n",
    "    # Print the available languages\n",
    "    print(\"Available languages:\")\n",
    "    print(\"en: English\")\n",
    "    print(\"es: Spanish\")\n",
    "    # Add more languages here\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"\\nOriginal text: {text_to_translate}\")\n",
    "    print(f\"Translated text: {translated_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a72a1e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available languages:\n",
      "af: Afrikaans\n",
      "am: Amharic\n",
      "ar: Arabic\n",
      "az: Azerbaijani\n",
      "be: Belarusian\n",
      "bg: Bulgarian\n",
      "bn: Bengali\n",
      "bs: Bosnian\n",
      "ca: Catalan\n",
      "ceb: Cebuano\n",
      "co: Corsican\n",
      "cs: Czech\n",
      "cy: Welsh\n",
      "da: Danish\n",
      "de: German\n",
      "el: Greek\n",
      "en: English\n",
      "eo: Esperanto\n",
      "es: Spanish\n",
      "et: Estonian\n",
      "eu: Basque\n",
      "fa: Persian\n",
      "fi: Finnish\n",
      "fr: French\n",
      "fy: Frisian\n",
      "ga: Irish\n",
      "gd: Scottish Gaelic\n",
      "gl: Galician\n",
      "gu: Gujarati\n",
      "ha: Hausa\n",
      "haw: Hawaiian\n",
      "he: Hebrew\n",
      "hi: Hindi\n",
      "hmn: Hmong\n",
      "hr: Croatian\n",
      "ht: Haitian Creole\n",
      "hu: Hungarian\n",
      "hy: Armenian\n",
      "id: Indonesian\n",
      "ig: Igbo\n",
      "is: Icelandic\n",
      "it: Italian\n",
      "iw: Hebrew (obsolete)\n",
      "ja: Japanese\n",
      "jv: Javanese\n",
      "ka: Georgian\n",
      "kk: Kazakh\n",
      "km: Khmer\n",
      "kn: Kannada\n",
      "ko: Korean\n",
      "ku: Kurdish\n",
      "ky: Kyrgyz\n",
      "la: Latin\n",
      "lb: Luxembourgish\n",
      "lo: Lao\n",
      "lt: Lithuanian\n",
      "lv: Latvian\n",
      "mg: Malagasy\n",
      "mi: Maori\n",
      "mk: Macedonian\n",
      "ml: Malayalam\n",
      "mn: Mongolian\n",
      "mr: Marathi\n",
      "ms: Malay\n",
      "mt: Maltese\n",
      "my: Burmese\n",
      "ne: Nepali\n",
      "nl: Dutch\n",
      "no: Norwegian\n",
      "ny: Nyanja\n",
      "or: Oriya\n",
      "pa: Punjabi\n",
      "pl: Polish\n",
      "ps: Pashto\n",
      "pt: Portuguese\n",
      "ro: Romanian\n",
      "ru: Russian\n",
      "rw: Kinyarwanda\n",
      "sd: Sindhi\n",
      "si: Sinhala\n",
      "sk: Slovak\n",
      "sl: Slovenian\n",
      "sm: Samoan\n",
      "sn: Shona\n",
      "so: Somali\n",
      "sq: Albanian\n",
      "sr: Serbian\n",
      "st: Southern Sotho\n",
      "su: Sundanese\n",
      "sv: Swedish\n",
      "sw: Swahili\n",
      "ta: Tamil\n",
      "te: Telugu\n",
      "tg: Tajik\n",
      "th: Thai\n",
      "tk: Turkmen\n",
      "tl: Tagalog\n",
      "tr: Turkish\n",
      "tt: Tatar\n",
      "ug: Uyghur\n",
      "uk: Ukrainian\n",
      "ur: Urdu\n",
      "uz: Uzbek\n",
      "vi: Vietnamese\n",
      "xh: Xhosa\n",
      "yi: Yiddish\n",
      "yo: Yoruba\n",
      "zh: Chinese\n",
      "zu: Zulu\n",
      "Enter the text to translate: lover\n",
      "Enter the code for the target language: ta\n",
      "\n",
      "Original text: lover\n",
      "Translated text: காதலன்\n"
     ]
    }
   ],
   "source": [
    "from translate import Translator\n",
    "from langdetect import detect\n",
    "\n",
    "def translate_text(text, to_lang):\n",
    "    try:\n",
    "        # Detect the language of the input text\n",
    "        from_lang = detect(text)\n",
    "        translator = Translator(from_lang=from_lang, to_lang=to_lang)\n",
    "        translation = translator.translate(text)\n",
    "        return translation\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "def print_available_languages():\n",
    "    print(\"Available languages:\")\n",
    "    print(\"af: Afrikaans\")\n",
    "    print(\"am: Amharic\")\n",
    "    print(\"ar: Arabic\")\n",
    "    print(\"az: Azerbaijani\")\n",
    "    print(\"be: Belarusian\")\n",
    "    print(\"bg: Bulgarian\")\n",
    "    print(\"bn: Bengali\")\n",
    "    print(\"bs: Bosnian\")\n",
    "    print(\"ca: Catalan\")\n",
    "    print(\"ceb: Cebuano\")\n",
    "    print(\"co: Corsican\")\n",
    "    print(\"cs: Czech\")\n",
    "    print(\"cy: Welsh\")\n",
    "    print(\"da: Danish\")\n",
    "    print(\"de: German\")\n",
    "    print(\"el: Greek\")\n",
    "    print(\"en: English\")\n",
    "    print(\"eo: Esperanto\")\n",
    "    print(\"es: Spanish\")\n",
    "    print(\"et: Estonian\")\n",
    "    print(\"eu: Basque\")\n",
    "    print(\"fa: Persian\")\n",
    "    print(\"fi: Finnish\")\n",
    "    print(\"fr: French\")\n",
    "    print(\"fy: Frisian\")\n",
    "    print(\"ga: Irish\")\n",
    "    print(\"gd: Scottish Gaelic\")\n",
    "    print(\"gl: Galician\")\n",
    "    print(\"gu: Gujarati\")\n",
    "    print(\"ha: Hausa\")\n",
    "    print(\"haw: Hawaiian\")\n",
    "    print(\"he: Hebrew\")\n",
    "    print(\"hi: Hindi\")\n",
    "    print(\"hmn: Hmong\")\n",
    "    print(\"hr: Croatian\")\n",
    "    print(\"ht: Haitian Creole\")\n",
    "    print(\"hu: Hungarian\")\n",
    "    print(\"hy: Armenian\")\n",
    "    print(\"id: Indonesian\")\n",
    "    print(\"ig: Igbo\")\n",
    "    print(\"is: Icelandic\")\n",
    "    print(\"it: Italian\")\n",
    "    print(\"iw: Hebrew (obsolete)\")\n",
    "    print(\"ja: Japanese\")\n",
    "    print(\"jv: Javanese\")\n",
    "    print(\"ka: Georgian\")\n",
    "    print(\"kk: Kazakh\")\n",
    "    print(\"km: Khmer\")\n",
    "    print(\"kn: Kannada\")\n",
    "    print(\"ko: Korean\")\n",
    "    print(\"ku: Kurdish\")\n",
    "    print(\"ky: Kyrgyz\")\n",
    "    print(\"la: Latin\")\n",
    "    print(\"lb: Luxembourgish\")\n",
    "    print(\"lo: Lao\")\n",
    "    print(\"lt: Lithuanian\")\n",
    "    print(\"lv: Latvian\")\n",
    "    print(\"mg: Malagasy\")\n",
    "    print(\"mi: Maori\")\n",
    "    print(\"mk: Macedonian\")\n",
    "    print(\"ml: Malayalam\")\n",
    "    print(\"mn: Mongolian\")\n",
    "    print(\"mr: Marathi\")\n",
    "    print(\"ms: Malay\")\n",
    "    print(\"mt: Maltese\")\n",
    "    print(\"my: Burmese\")\n",
    "    print(\"ne: Nepali\")\n",
    "    print(\"nl: Dutch\")\n",
    "    print(\"no: Norwegian\")\n",
    "    print(\"ny: Nyanja\")\n",
    "    print(\"or: Oriya\")\n",
    "    print(\"pa: Punjabi\")\n",
    "    print(\"pl: Polish\")\n",
    "    print(\"ps: Pashto\")\n",
    "    print(\"pt: Portuguese\")\n",
    "    print(\"ro: Romanian\")\n",
    "    print(\"ru: Russian\")\n",
    "    print(\"rw: Kinyarwanda\")\n",
    "    print(\"sd: Sindhi\")\n",
    "    print(\"si: Sinhala\")\n",
    "    print(\"sk: Slovak\")\n",
    "    print(\"sl: Slovenian\")\n",
    "    print(\"sm: Samoan\")\n",
    "    print(\"sn: Shona\")\n",
    "    print(\"so: Somali\")\n",
    "    print(\"sq: Albanian\")\n",
    "    print(\"sr: Serbian\")\n",
    "    print(\"st: Southern Sotho\")\n",
    "    print(\"su: Sundanese\")\n",
    "    print(\"sv: Swedish\")\n",
    "    print(\"sw: Swahili\")\n",
    "    print(\"ta: Tamil\")\n",
    "    print(\"te: Telugu\")\n",
    "    print(\"tg: Tajik\")\n",
    "    print(\"th: Thai\")\n",
    "    print(\"tk: Turkmen\")\n",
    "    print(\"tl: Tagalog\")\n",
    "    print(\"tr: Turkish\")\n",
    "    print(\"tt: Tatar\")\n",
    "    print(\"ug: Uyghur\")\n",
    "    print(\"uk: Ukrainian\")\n",
    "    print(\"ur: Urdu\")\n",
    "    print(\"uz: Uzbek\")\n",
    "    print(\"vi: Vietnamese\")\n",
    "    print(\"xh: Xhosa\")\n",
    "    print(\"yi: Yiddish\")\n",
    "    print(\"yo: Yoruba\")\n",
    "    print(\"zh: Chinese\")\n",
    "    print(\"zu: Zulu\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Print the available languages\n",
    "    print_available_languages()\n",
    "    \n",
    "    # Get input from the user\n",
    "    text_to_translate = input(\"Enter the text to translate: \")\n",
    "    to_language = input(\"Enter the code for the target language: \")\n",
    "    \n",
    "    # Perform translation\n",
    "    translated_text = translate_text(text_to_translate, to_language)\n",
    "    \n",
    "    \n",
    "    # Print the results\n",
    "    print(\"\\nOriginal text:\", text_to_translate)\n",
    "    print(\"Translated text:\", translated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4670d64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\hp5cd\\.cache\\huggingface\\token\n",
      "Login successful\n",
      "Welcome! Type 'exit' to end the session.\n",
      "You: hi\n",
      "Bot: Hello! How can I assist you today? 👋\n",
      "You: flower\n",
      "Bot: \n",
      "\n",
      "# Sunflower\n",
      "\n",
      "## Helianthus annuus\n",
      "\n",
      "- Sunflowers are annual plants and native to North America, specifically to the western south.\n",
      "- The sunflower is the state flower of Kansas.\n",
      "- The sunflower is a symbol of adoration, loyalty, and longevity.\n",
      "- Sunflowers grow up to 10 feet tall.\n",
      "- The sunflower head is made up of thousands of tiny individual flowers.\n",
      "- Each sunflower plant can produce up to 5000 seeds.\n",
      "- Sunflowers are very good for the environment. They help with erosion control, they provide food for many species of wildlife, and they can help clean up soil contaminated with heavy metals.\n",
      "- Sunflowers can be used for biofuel.\n",
      "- The sunflower plant is edible. The seeds are eaten raw or roasted, and the oil is used for cooking and making margarine. The leaves can be used as greens, and the stalks can be used as a vegetable.\n",
      "- The sunflower plant can be used to make sunflower oil, which is used for cooking, making margarine, and in cosmetics.\n",
      "- The sunflower plant can be used to make sunflower lecithin, which is used in food and cosmetics.\n",
      "- The sunflower plant can be used to make sunflower meal, which is used as animal feed.\n",
      "- The sunflower plant can be used to make sunflower oil, which is used as a fuel for diesel engines.\n",
      "- The sunflower plant can be used to make sunflower biofuel, which is a renewable energy source.\n",
      "- The sunflower plant can be used to make sunflower oil, which is used as a fuel for biodiesel engines.\n",
      "- The sunflower plant can be used to make sunflower biofuel, which is a renewable energy source.\n",
      "- The sunflower plant can be used to make sunflower oil, which is used as a fuel for biodiesel engines.\n",
      "- The sunflower plant can be used to make sunflower biofuel, which is a renewable energy source.\n",
      "- The sunflower plant can be used to make sunflower oil, which is used as a fuel for\n",
      "You: god\n",
      "Bot:  of war 3\n",
      "\n",
      "# God of War 3: How to Get All of the Gorgon Eye's\n",
      "\n",
      "The Gorgon Eye is one of the more important items in God of War 3.  It's a relic that is used to open up secret areas in the game.  There are a total of 5 Gorgon Eye's that you need to collect, but only 4 of them are accessible at one time.\n",
      "\n",
      "The 5th Gorgon Eye is not available until you have completed the game and started a new game+.  I'll be covering how to get the Gorgon Eye's in a future post, but for now, let's focus on the 4 you can collect in a single play through.\n",
      "\n",
      "In order to find the Gorgon Eye's you'll need to find and defeat the three Sisters of Fate, the Weaver, the Spinner, and the Fate.  Once you defeat them, they will drop a Fate's Thread.  These are used to open up secret doors.\n",
      "\n",
      "Once you've collected a Fate's Thread you'll be able to use it to open up the secret doors that lead to the Gorgon Eye's.  To open a secret door you'll need to look for a door that has the symbol for the Gorgon Eye on it.  Once you find one, you can use the Fate's Thread to open it up.\n",
      "\n",
      "The Gorgon Eye's are located in the following areas:\n",
      "\n",
      "1.  The entrance to the Underworld\n",
      "\n",
      "2.  The Garden of the Gods (this one is a bit tricky to find, you'll need to go back to the Garden after you've defeated the Hydra, and you'll find it in the back of the Garden)\n",
      "\n",
      "3.  The Temple of Ares (this one is a bit tricky to find, you'll need to go back to the Temple after you've defeated the Minotaur and the Titan, and you'll find it in the back of the Temple)\n",
      "\n",
      "4.  The Vault of Hades (this one is a bit tricky to find, you'll need to go back to the Vault after you've defeated the Titan, and you'll find it in the back of the\n",
      "You: joke\n",
      "Bot:  = \"Why don't scientists trust atoms? Because they make up everything!\";\n",
      "\n",
      "function getJoke() {\n",
      "    return joke;\n",
      "}\n",
      "\n",
      "function setJoke(newJoke) {\n",
      "    joke = newJoke;\n",
      "}\n",
      "\n",
      "// Test\n",
      "console.log(getJoke());\n",
      "setJoke(\"Why did the chicken cross the road? To get to the other side!\");\n",
      "console.log(getJoke());\n",
      "You: flower\n",
      "Bot: \n",
      "\n",
      "# Sunflower\n",
      "\n",
      "## Helianthus annuus\n",
      "\n",
      "- Sunflowers are annual plants and native to North America, specifically to the western south.\n",
      "- The sunflower is the state flower of Kansas.\n",
      "- The sunflower is a symbol of adoration, loyalty, and longevity.\n",
      "- Sunflowers grow up to 10 feet tall.\n",
      "- The sunflower head is made up of thousands of tiny individual flowers.\n",
      "- Each sunflower plant can produce up to 5000 seeds.\n",
      "- Sunflowers are very good for the environment. They help with erosion control, they provide food for many species of wildlife, and they can help clean up soil contaminated with heavy metals.\n",
      "- Sunflowers can be used for biofuel.\n",
      "- The sunflower plant is edible. The seeds are eaten raw or roasted, and the oil is used for cooking and making margarine. The leaves can be used as greens, and the stalks can be used as a vegetable.\n",
      "- The sunflower plant can be used to make sunflower oil, which is used for cooking, making margarine, and in cosmetics.\n",
      "- The sunflower plant can be used to make sunflower lecithin, which is used in food and cosmetics.\n",
      "- The sunflower plant can be used to make sunflower meal, which is used as animal feed.\n",
      "- The sunflower plant can be used to make sunflower oil, which is used as a fuel for diesel engines.\n",
      "- The sunflower plant can be used to make sunflower biofuel, which is a renewable energy source.\n",
      "- The sunflower plant can be used to make sunflower oil, which is used as a fuel for biodiesel engines.\n",
      "- The sunflower plant can be used to make sunflower biofuel, which is a renewable energy source.\n",
      "- The sunflower plant can be used to make sunflower oil, which is used as a fuel for biodiesel engines.\n",
      "- The sunflower plant can be used to make sunflower biofuel, which is a renewable energy source.\n",
      "- The sunflower plant can be used to make sunflower oil, which is used as a fuel for\n",
      "You: net\n",
      "Bot: zwerk\n",
      "\n",
      "# Netzwerk\n",
      "\n",
      "### The network of the \"Alliance for Migration and Diversity\"\n",
      "\n",
      "The \"Alliance for Migration and Diversity\" is an alliance of 150 organizations from the civil society, business, politics, science, media and culture. The network was founded in 2016 and is coordinated by the \"German National Council for Migration\" (RAD) and the \"German Foundation for Integration\" (Dvi). The network aims to promote the positive aspects of migration and diversity.\n",
      "\n",
      "The network of the \"Alliance for Migration and Diversity\" is characterized by the following principles:\n",
      "\n",
      "1. A comprehensive approach: The network deals with the entire spectrum of migration and diversity, from immigration and integration to the prevention of discrimination and the promotion of diversity.\n",
      "2. A broad-based approach: The network brings together organizations from a wide range of sectors and fields, including civil society, business, politics, science, media and culture.\n",
      "3. A solution-oriented approach: The network focuses on finding solutions to the challenges posed by migration and diversity, and on promoting a positive narrative about migration and diversity.\n",
      "4. A collaborative approach: The network works together with various actors, including government agencies, non-governmental organizations, and other stakeholders, to achieve its goals.\n",
      "5. A focus on evidence-based policy-making: The network advocates for evidence-based policy-making, and for policies that are based on research and best practices.\n",
      "\n",
      "The network of the \"Alliance for Migration and Diversity\" is active at the national and regional level, and works to promote a positive narrative about migration and diversity, to advocate for evidence-based policies, and to support the integration of migrants and refugees. The network organizes events, publishes reports and recommendations, and engages in dialogue with policymakers and other stakeholders.\n",
      "\n",
      "The network is open to new members, and welcomes organizations from all sectors and fields that share the goals of the \"Alliance for Migration and Diversity.\" To become a member, organizations can contact the coordinating institutions, the \"German National Council for Migration\" (RAD) and the \"German Foundation for Integration\" (Dvi).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: Inter net\n",
      "Bot: \n",
      "\n",
      "# Internet of Things (IoT)\n",
      "\n",
      "The Internet of Things (IoT) is a network of physical devices, vehicles, buildings, and other items embedded with electronics, software, sensors, and network connectivity that enable these objects to collect and exchange data.\n",
      "\n",
      "The IoT allows objects to be sensed and controlled remotely across existing network infrastructure, creating opportunities for more direct integration between the physical world and computer-based systems, resulting in improved efficiency, accuracy, and economic benefit.\n",
      "\n",
      "IoT devices are often connected to the Internet, and they can be managed using various protocols, including MQTT, CoAP (Constrained Application Protocol), and HTTP. They can be used for a wide range of applications, such as smart homes, industrial automation, wearable devices, and connected cars.\n",
      "\n",
      "The IoT market is growing rapidly, and it is expected to have a significant impact on various industries, including healthcare, manufacturing, retail, transportation, and agriculture. It is also expected to create new opportunities for businesses and individuals to create innovative products and services.\n",
      "\n",
      "However, the IoT also presents challenges, such as security and privacy concerns, as well as the need for interoperability between different devices and systems. It is essential to address these challenges to ensure the safe and effective deployment of IoT technologies.\n",
      "\n",
      "Overall, the Internet of Things is a transformative technology that has the potential to revolutionize various industries and improve the quality of life for people around the world.\n",
      "\n",
      "To learn more about the Internet of Things, check out these resources:\n",
      "\n",
      "* [Internet of Things (IoT)](https://en.wikipedia.org/wiki/Internet_of_things) - Wikipedia article on the Internet of Things\n",
      "* [Internet of Things (IoT)](https://www.ibm.com/topics/internet-of-things) - IBM's resource center on the Internet of Things\n",
      "* [Internet of Things (IoT)](https://www.gartner.com/en/information-technology/internet-of-things) - Gartner's resource center on the Internet of Things\n",
      "* [Internet of Things (IoT)](https://www.forbes.com/internet-of-things/) - Forbes' resource center on the Internet of Things\n",
      "* [Internet of Things (IoT)](https\n",
      "You: exit\n",
      "Bot: Exiting the session. Goodbye! 👋\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from datetime import datetime\n",
    "\n",
    "# Set your Hugging Face API token using environment variable for security\n",
    "sec_key = \"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\"\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = sec_key\n",
    "\n",
    "# Repository ID for the model\n",
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "# Initialize the HuggingFaceEndpoint\n",
    "llm = HuggingFaceEndpoint(repo_id=repo_id, temperature=0.7)\n",
    "\n",
    "# Common phrases dictionary with emojis\n",
    "common_phrases = {\n",
    "    \"hi\": \"Hello! How can I assist you today? 👋\",\n",
    "    \"what is your name\": \"Hi! My name is Artificial Intelligence? 👋\",\n",
    "    \"name\": \"Hi! My name is Artificial Intelligence? 👋\",\n",
    "    \"hello\": \"Hi there! How can I help you? 👋\",\n",
    "    \"hey\": \"Hey! What's up? 👋\",\n",
    "    \"how are you\": \"Thank you for asking, I'm Good How about you?😊\",\n",
    "    \"howdy\": \"Howdy! What can I do for you? 🤠\",\n",
    "    \"greetings\": \"Greetings! How can I assist? 🙌\",\n",
    "    \"how are you\": \"I'm just a bot, but I'm here to help you! How can I assist you today? 😊\",\n",
    "    \"what's up\": \"Not much, just here to assist you! What can I help you with? 😊\",\n",
    "    \"help me\": \"Sure, I'm here to help! What do you need assistance with? 🤔\",\n",
    "    \"thank you\": \"You're welcome! If you have any other questions, feel free to ask. 😊\",\n",
    "    \"thanks\": \"You're welcome! Let me know if there's anything else I can do for you. 😊\",\n",
    "    \"bye\": \"Bye!, Let me know if there's anything else I can do for you. 😊\",\n",
    "    \"Good bye\": \"Bye!, Let me know if there's anything else I can do for you. 😊\",\n",
    "    \"i got a good mark\": \"WOW!, All the best 😊\",\n",
    "}\n",
    "\n",
    "# Function to handle time-related queries\n",
    "def handle_time_query():\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    return f\"The current time is {current_time}\"\n",
    "\n",
    "# Function to ask questions to the LLM\n",
    "def ask_question(question: str):\n",
    "    if question.lower() == 'time':\n",
    "        return handle_time_query()\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke(question, max_length=128)  # Set max_length here\n",
    "        if any(keyword in question.lower() for keyword in [\"program\", \"code\", \"script\"]):\n",
    "            # Extract and return only the code block from the response\n",
    "            start = response.find(\"```\")\n",
    "            end = response.rfind(\"```\")\n",
    "            if start != -1 and end != -1:\n",
    "                code_block = response[start+3:end].strip()\n",
    "                return code_block\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "# Function to log conversation to a text file with UTF-8 encoding\n",
    "def log_conversation(user_message, bot_response):\n",
    "    with open(\"conversation_log.txt\", \"a\", encoding=\"utf-8\") as log_file:\n",
    "        log_file.write(f\"User: {user_message}\\n\")\n",
    "        log_file.write(f\"Bot: {bot_response}\\n\\n\")\n",
    "\n",
    "def main():\n",
    "    print(\"Welcome! Type 'exit' to end the session.\")\n",
    "    while True:\n",
    "        question = input(\"You: \").lower()\n",
    "        if not question:\n",
    "            print(\"Please provide a question.\")\n",
    "            continue\n",
    "        \n",
    "        if question in common_phrases:\n",
    "            response = common_phrases[question]\n",
    "            log_conversation(question, response)\n",
    "            print(f\"Bot: {response}\")\n",
    "            continue\n",
    "        \n",
    "        if question == 'exit':\n",
    "            response = \"Exiting the session. Goodbye! 👋\"\n",
    "            log_conversation(question, response)\n",
    "            print(f\"Bot: {response}\")\n",
    "            break\n",
    "        elif question.startswith('sum'):\n",
    "            try:\n",
    "                _, a, b = question.split()\n",
    "                a, b = int(a), int(b)\n",
    "                sum_result = a + b\n",
    "                response = f\"Sum of {a} and {b} is: {sum_result}\"\n",
    "                log_conversation(question, response)\n",
    "                print(f\"Bot: {response}\")\n",
    "            except ValueError:\n",
    "                response = \"Invalid input for sum. Please provide two integers.\"\n",
    "                log_conversation(question, response)\n",
    "                print(f\"Bot: {response}\")\n",
    "        else:\n",
    "            try:\n",
    "                response = ask_question(question)\n",
    "                log_conversation(question, response)\n",
    "                print(f\"Bot: {response}\")\n",
    "            except Exception as e:\n",
    "                response = f\"Error: {str(e)}\"\n",
    "                log_conversation(question, response)\n",
    "                print(f\"Bot: {response}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dcf7833",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3.\n401 Client Error. (Request ID: Root=1-665ab802-5eef458e3b316e572984120b;f5269fcf-2c22-403b-ae79-f73d72a23b79)\n\nCannot access gated repo for url https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3/resolve/main/config.json.\nAccess to model mistralai/Mistral-7B-Instruct-v0.3 is restricted. You must be authenticated to access it.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\utils\\_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 304\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\requests\\models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mGatedRepoError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\hub.py:399\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 399\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m hf_hub_download(\n\u001b[0;32m    400\u001b[0m         path_or_repo_id,\n\u001b[0;32m    401\u001b[0m         filename,\n\u001b[0;32m    402\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(subfolder) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m subfolder,\n\u001b[0;32m    403\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[0;32m    404\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m    405\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m    406\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[0;32m    407\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[0;32m    408\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m    409\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[0;32m    410\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m    411\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    412\u001b[0m     )\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:1221\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[0;32m   1220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_cache_dir(\n\u001b[0;32m   1222\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[0;32m   1223\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m   1224\u001b[0m         \u001b[38;5;66;03m# File info\u001b[39;00m\n\u001b[0;32m   1225\u001b[0m         repo_id\u001b[38;5;241m=\u001b[39mrepo_id,\n\u001b[0;32m   1226\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[0;32m   1227\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[0;32m   1228\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m   1229\u001b[0m         \u001b[38;5;66;03m# HTTP info\u001b[39;00m\n\u001b[0;32m   1230\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m   1231\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m   1232\u001b[0m         etag_timeout\u001b[38;5;241m=\u001b[39metag_timeout,\n\u001b[0;32m   1233\u001b[0m         endpoint\u001b[38;5;241m=\u001b[39mendpoint,\n\u001b[0;32m   1234\u001b[0m         \u001b[38;5;66;03m# Additional options\u001b[39;00m\n\u001b[0;32m   1235\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m   1236\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[0;32m   1237\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:1325\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[1;34m(cache_dir, repo_id, filename, repo_type, revision, headers, proxies, etag_timeout, endpoint, local_files_only, force_download)\u001b[0m\n\u001b[0;32m   1324\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[1;32m-> 1325\u001b[0m     _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n\u001b[0;32m   1327\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:1823\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[1;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[0;32m   1821\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[0;32m   1822\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[1;32m-> 1823\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[0;32m   1824\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1825\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:1722\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[1;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[0;32m   1721\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1722\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m get_hf_file_metadata(url\u001b[38;5;241m=\u001b[39murl, proxies\u001b[38;5;241m=\u001b[39mproxies, timeout\u001b[38;5;241m=\u001b[39metag_timeout, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[0;32m   1723\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:1645\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[1;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[0;32m   1644\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[1;32m-> 1645\u001b[0m r \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[0;32m   1646\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1647\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   1648\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m   1649\u001b[0m     allow_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1650\u001b[0m     follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1651\u001b[0m     proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m   1652\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m   1653\u001b[0m )\n\u001b[0;32m   1654\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:372\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[1;32m--> 372\u001b[0m     response \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[0;32m    373\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    374\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    375\u001b[0m         follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    376\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:396\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    395\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m--> 396\u001b[0m hf_raise_for_status(response)\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\utils\\_errors.py:321\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    318\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot access gated repo for url \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m     )\n\u001b[1;32m--> 321\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GatedRepoError(message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_message \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccess to this resource is disabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mGatedRepoError\u001b[0m: 401 Client Error. (Request ID: Root=1-665ab802-5eef458e3b316e572984120b;f5269fcf-2c22-403b-ae79-f73d72a23b79)\n\nCannot access gated repo for url https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3/resolve/main/config.json.\nAccess to model mistralai/Mistral-7B-Instruct-v0.3 is restricted. You must be authenticated to access it.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m repo_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistralai/Mistral-7B-Instruct-v0.3\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Initialize the HuggingFaceEndpoint (simplified for transformers pipeline)\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m llm \u001b[38;5;241m=\u001b[39m pipeline(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m'\u001b[39m, model\u001b[38;5;241m=\u001b[39mrepo_id)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Common phrases dictionary with emojis\u001b[39;00m\n\u001b[0;32m     19\u001b[0m common_phrases \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhi\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello! How can I assist you today? 👋\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhat is your name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHi! My name is Artificial Intelligence? 👋\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi got a good mark\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWOW! All the best 😊\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     35\u001b[0m }\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pipelines\\__init__.py:816\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    813\u001b[0m                 adapter_config \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m    814\u001b[0m                 model \u001b[38;5;241m=\u001b[39m adapter_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase_model_name_or_path\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 816\u001b[0m     config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    817\u001b[0m         model, _from_pipeline\u001b[38;5;241m=\u001b[39mtask, code_revision\u001b[38;5;241m=\u001b[39mcode_revision, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs\n\u001b[0;32m    818\u001b[0m     )\n\u001b[0;32m    819\u001b[0m     hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39m_commit_hash\n\u001b[0;32m    821\u001b[0m custom_tasks \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\auto\\configuration_auto.py:934\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    931\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    932\u001b[0m code_revision \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 934\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m PretrainedConfig\u001b[38;5;241m.\u001b[39mget_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    935\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    936\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\configuration_utils.py:632\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    630\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[1;32m--> 632\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_config_dict(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[0;32m    634\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\configuration_utils.py:689\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[1;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[0;32m    685\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[1;32m--> 689\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[0;32m    690\u001b[0m         pretrained_model_name_or_path,\n\u001b[0;32m    691\u001b[0m         configuration_file,\n\u001b[0;32m    692\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m    693\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[0;32m    694\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m    695\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[0;32m    696\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    697\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m    698\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[0;32m    699\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m    700\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39msubfolder,\n\u001b[0;32m    701\u001b[0m         _commit_hash\u001b[38;5;241m=\u001b[39mcommit_hash,\n\u001b[0;32m    702\u001b[0m     )\n\u001b[0;32m    703\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# the original exception.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\utils\\hub.py:417\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_gated_repo:\n\u001b[0;32m    416\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n\u001b[1;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    418\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to have access to it at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    420\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    424\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    425\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    426\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`token=<your_token>`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    427\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3.\n401 Client Error. (Request ID: Root=1-665ab802-5eef458e3b316e572984120b;f5269fcf-2c22-403b-ae79-f73d72a23b79)\n\nCannot access gated repo for url https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3/resolve/main/config.json.\nAccess to model mistralai/Mistral-7B-Instruct-v0.3 is restricted. You must be authenticated to access it."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Replace this with the correct import for your environment\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from transformers import pipeline\n",
    "\n",
    "# Set your Hugging Face API token using environment variable for security\n",
    "sec_key = \"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\"\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = sec_key\n",
    "\n",
    "# Repository ID for the model\n",
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "# Initialize the HuggingFaceEndpoint (simplified for transformers pipeline)\n",
    "llm = pipeline('text-generation', model=repo_id)\n",
    "\n",
    "# Common phrases dictionary with emojis\n",
    "common_phrases = {\n",
    "    \"hi\": \"Hello! How can I assist you today? 👋\",\n",
    "    \"what is your name\": \"Hi! My name is Artificial Intelligence? 👋\",\n",
    "    \"name\": \"Hi! My name is Artificial Intelligence? 👋\",\n",
    "    \"hello\": \"Hi there! How can I help you? 👋\",\n",
    "    \"hey\": \"Hey! What's up? 👋\",\n",
    "    \"how are you\": \"Thank you for asking, I'm Good. How about you?😊\",\n",
    "    \"howdy\": \"Howdy! What can I do for you? 🤠\",\n",
    "    \"greetings\": \"Greetings! How can I assist? 🙌\",\n",
    "    \"what's up\": \"Not much, just here to assist you! What can I help you with? 😊\",\n",
    "    \"help me\": \"Sure, I'm here to help! What do you need assistance with? 🤔\",\n",
    "    \"thank you\": \"You're welcome! If you have any other questions, feel free to ask. 😊\",\n",
    "    \"thanks\": \"You're welcome! Let me know if there's anything else I can do for you. 😊\",\n",
    "    \"bye\": \"Bye! Let me know if there's anything else I can do for you. 😊\",\n",
    "    \"good bye\": \"Bye! Let me know if there's anything else I can do for you. 😊\",\n",
    "    \"i got a good mark\": \"WOW! All the best 😊\",\n",
    "}\n",
    "\n",
    "# Function to handle time-related queries\n",
    "def handle_time_query():\n",
    "    current_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "    return f\"The current time is {current_time}\"\n",
    "\n",
    "# Function to ask questions to the LLM\n",
    "def ask_question(question: str):\n",
    "    if question.lower() == 'time':\n",
    "        return handle_time_query()\n",
    "\n",
    "    try:\n",
    "        response = llm(question, max_length=128, num_return_sequences=1)\n",
    "        response_text = response[0]['generated_text']\n",
    "        if any(keyword in question.lower() for keyword in [\"program\", \"code\", \"script\"]):\n",
    "            # Extract and return only the code block from the response\n",
    "            start = response_text.find(\"```\")\n",
    "            end = response_text.rfind(\"```\")\n",
    "            if start != -1 and end != -1:\n",
    "                code_block = response_text[start + 3:end].strip()\n",
    "                return code_block\n",
    "        return response_text\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "# Function to log conversation to a text file with UTF-8 encoding\n",
    "def log_conversation(user_message, bot_response):\n",
    "    with open(\"conversation_log.txt\", \"a\", encoding=\"utf-8\") as log_file:\n",
    "        log_file.write(f\"User: {user_message}\\n\")\n",
    "        log_file.write(f\"Bot: {bot_response}\\n\\n\")\n",
    "\n",
    "def main():\n",
    "    print(\"Welcome! Type 'exit' to end the session.\")\n",
    "    while True:\n",
    "        question = input(\"You: \").lower()\n",
    "        if not question:\n",
    "            print(\"Please provide a question.\")\n",
    "            continue\n",
    "\n",
    "        if question in common_phrases:\n",
    "            response = common_phrases[question]\n",
    "            log_conversation(question, response)\n",
    "            print(f\"Bot: {response}\")\n",
    "            continue\n",
    "\n",
    "        if question == 'exit':\n",
    "            response = \"Exiting the session. Goodbye! 👋\"\n",
    "            log_conversation(question, response)\n",
    "            print(f\"Bot: {response}\")\n",
    "            break\n",
    "        elif question.startswith('sum'):\n",
    "            try:\n",
    "                _, a, b = question.split()\n",
    "                a, b = int(a), int(b)\n",
    "                sum_result = a + b\n",
    "                response = f\"Sum of {a} and {b} is: {sum_result}\"\n",
    "                log_conversation(question, response)\n",
    "                print(f\"Bot: {response}\")\n",
    "            except ValueError:\n",
    "                response = \"Invalid input for sum. Please provide two integers.\"\n",
    "                log_conversation(question, response)\n",
    "                print(f\"Bot: {response}\")\n",
    "        else:\n",
    "            try:\n",
    "                response = ask_question(question)\n",
    "                log_conversation(question, response)\n",
    "                print(f\"Bot: {response}\")\n",
    "            except Exception as e:\n",
    "                response = f\"Error: {str(e)}\"\n",
    "                log_conversation(question, response)\n",
    "                print(f\"Bot: {response}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa741757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
